{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research question 2: Do decision trees produce more intuitive explanations than LIME?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask==2.0.2 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (2.0.2)\n",
      "Requirement already satisfied: pillow==9.3.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (9.3.0)\n",
      "Requirement already satisfied: pandas==1.4.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (1.4.0)\n",
      "Requirement already satisfied: scikit-learn==1.3.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: flask-cors==3.0.10 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (3.0.10)\n",
      "Requirement already satisfied: pymongo==4.3.3 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (4.3.3)\n",
      "Requirement already satisfied: numpy>=1.22.1 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (1.24.3)\n",
      "Requirement already satisfied: scikit-image==0.19.3 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (0.19.3)\n",
      "Requirement already satisfied: pytest==7.1.2 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (7.1.2)\n",
      "Requirement already satisfied: dice-ml==0.9 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (0.9)\n",
      "Requirement already satisfied: mpire==2.6.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (2.6.0)\n",
      "Requirement already satisfied: lime==0.2.0.1 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (0.2.0.1)\n",
      "Requirement already satisfied: tensorflow==2.13.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from -r requirements.txt (line 13)) (2.13.0)\n",
      "Requirement already satisfied: matplotlib==3.7.1 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (3.7.1)\n",
      "Requirement already satisfied: Werkzeug>=2.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from flask==2.0.2->-r requirements.txt (line 1)) (2.3.6)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from flask==2.0.2->-r requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from flask==2.0.2->-r requirements.txt (line 1)) (2.1.2)\n",
      "Requirement already satisfied: click>=7.1.2 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from flask==2.0.2->-r requirements.txt (line 1)) (8.1.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from pandas==1.4.0->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from pandas==1.4.0->-r requirements.txt (line 3)) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from scikit-learn==1.3.0->-r requirements.txt (line 4)) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from scikit-learn==1.3.0->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from scikit-learn==1.3.0->-r requirements.txt (line 4)) (3.2.0)\n",
      "Requirement already satisfied: Six in /opt/homebrew/opt/six/lib/python3.11/site-packages (from flask-cors==3.0.10->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from pymongo==4.3.3->-r requirements.txt (line 6)) (2.4.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from scikit-image==0.19.3->-r requirements.txt (line 8)) (3.1)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from scikit-image==0.19.3->-r requirements.txt (line 8)) (2.31.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from scikit-image==0.19.3->-r requirements.txt (line 8)) (2023.7.18)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from scikit-image==0.19.3->-r requirements.txt (line 8)) (1.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from scikit-image==0.19.3->-r requirements.txt (line 8)) (23.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from pytest==7.1.2->-r requirements.txt (line 9)) (23.1.0)\n",
      "Requirement already satisfied: iniconfig in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from pytest==7.1.2->-r requirements.txt (line 9)) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from pytest==7.1.2->-r requirements.txt (line 9)) (1.2.0)\n",
      "Requirement already satisfied: py>=1.8.2 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from pytest==7.1.2->-r requirements.txt (line 9)) (1.11.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from pytest==7.1.2->-r requirements.txt (line 9)) (2.0.1)\n",
      "Requirement already satisfied: jsonschema in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from dice-ml==0.9->-r requirements.txt (line 10)) (4.18.3)\n",
      "Requirement already satisfied: h5py in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from dice-ml==0.9->-r requirements.txt (line 10)) (3.9.0)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from dice-ml==0.9->-r requirements.txt (line 10)) (4.65.0)\n",
      "Requirement already satisfied: pygments>=2.0 in /opt/homebrew/opt/pygments/lib/python3.11/site-packages (from mpire==2.6.0->-r requirements.txt (line 11)) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-macos==2.13.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from tensorflow==2.13.0->-r requirements.txt (line 13)) (2.13.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 14)) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 14)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 14)) (4.41.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 14)) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 14)) (3.0.9)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (16.0.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (4.21.12)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (67.6.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (1.56.2)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (2.13.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: httpcore>=0.17.3 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from dnspython<3.0.0,>=1.16.0->pymongo==4.3.3->-r requirements.txt (line 6)) (0.17.3)\n",
      "Requirement already satisfied: sniffio<2.0,>=1.1 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from dnspython<3.0.0,>=1.16.0->pymongo==4.3.3->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from Jinja2>=3.0->flask==2.0.2->-r requirements.txt (line 1)) (2.1.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from jsonschema->dice-ml==0.9->-r requirements.txt (line 10)) (2023.6.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from jsonschema->dice-ml==0.9->-r requirements.txt (line 10)) (0.29.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from jsonschema->dice-ml==0.9->-r requirements.txt (line 10)) (0.8.10)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/homebrew/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (0.40.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from httpcore>=0.17.3->dnspython<3.0.0,>=1.16.0->pymongo==4.3.3->-r requirements.txt (line 6)) (0.14.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from httpcore>=0.17.3->dnspython<3.0.0,>=1.16.0->pymongo==4.3.3->-r requirements.txt (line 6)) (3.7.1)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from httpcore>=0.17.3->dnspython<3.0.0,>=1.16.0->pymongo==4.3.3->-r requirements.txt (line 6)) (2023.5.7)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (0.7.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from anyio<5.0,>=3.0->httpcore>=0.17.3->dnspython<3.0.0,>=1.16.0->pymongo==4.3.3->-r requirements.txt (line 6)) (3.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (3.2.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow==2.13.0->-r requirements.txt (line 13)) (3.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from skimage.transform import resize\n",
    "\n",
    "blackbox_model = ResNet50(weights='imagenet', include_top=True, input_shape=(224, 224, 3))\n",
    "\n",
    "def preprocess_images(img_array):\n",
    "    img_array = np.array([tf.image.resize(img_to_array(img), (224, 224)) for img in img_array])\n",
    "    return preprocess_input(img_array)\n",
    "\n",
    "def black_box_classify(img_array,convert_to_nr=True):\n",
    "    preprocessed_imgs = preprocess_images(img_array)\n",
    "    predictions = blackbox_model.predict(preprocessed_imgs)\n",
    "    prediction_labels = decode_predictions(predictions, top = 1)\n",
    "    labels_as_str = [row[0][1] for row in prediction_labels]\n",
    "    if convert_to_nr:\n",
    "        label_as_nr = label_encoder.transform(labels_as_str)\n",
    "        return [[l]for l in label_as_nr]\n",
    "    return [[l]for l in labels_as_str]\n",
    "\n",
    "def black_box_lime(temp):\n",
    "    resized_temp = resize(temp, (224, 224), mode='reflect', preserve_range=True).astype(np.uint8)\n",
    "    resized_temp = np.expand_dims(resized_temp, axis=0)\n",
    "    predictions = blackbox_model.predict(resized_temp)\n",
    "    prediction_labels = decode_predictions(predictions, top = 1)\n",
    "    labels_as_str = [row[0][1] for row in prediction_labels]\n",
    "    label_as_nr = label_encoder.transform(labels_as_str)\n",
    "    return [[l]for l in label_as_nr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 31s 613ms/step\n",
      "Total number of images 1592\n",
      "Number of images used 10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "base_path = \"/Users/karlgustav/Documents/GitHub/study/master-thesis/server/src/research/\"\n",
    "# base_path = \"/Users/karl-gustav.kallasmaa/Documents/Projects/master-thesis/server/src/\"\n",
    "all_labels_path = f\"{base_path}all_classes.txt\"\n",
    "all_concepts_path = f\"{base_path}all_concepts.txt\"\n",
    "masks_path = f\"{base_path}data/masks.pkl\"\n",
    "img_path = f\"{base_path}data/resized_imgs.pkl\"\n",
    "labels_path = f\"{base_path}data/classes.pkl\"\n",
    "ade_path = f\"{base_path}data/objectInfo150.csv\"\n",
    "\n",
    "ade_classes = pd.read_csv(ade_path)\n",
    "\n",
    "images = []\n",
    "masks = []\n",
    "unique_labels = []\n",
    "with open(masks_path, 'rb') as f:\n",
    "    masks = pickle.load(f)\n",
    "with open(img_path, 'rb') as f:\n",
    "    images = pickle.load(f)\n",
    "with open(all_labels_path) as f:\n",
    "    lines = f.read().splitlines()\n",
    "    lines = [l.replace(' ', '_') for l in lines]\n",
    "    unique_labels = np.array(list(set(lines)))\n",
    "\n",
    "labels = black_box_classify(images,False)\n",
    "labels = [l[0] for l in labels]\n",
    "\n",
    "all_concept_values = ade_classes['Name'].tolist()\n",
    "UNIQUE_CONCEPT_VALUES = sorted(list(set(all_concept_values)))\n",
    "NR_OF_UNIQUE_CONCEPTS = len(UNIQUE_CONCEPT_VALUES)\n",
    "\n",
    "\n",
    "image_hex_index_map = {hashlib.sha1(np.array(img).view(np.uint8)).hexdigest(): i for i,img in enumerate(images)}\n",
    "\n",
    "index_img_map = {i:img for i,img in enumerate(images)}\n",
    "index_label_map = {i:label for i,label in enumerate(labels)}\n",
    "index_mask_map = {i:mask for i,mask in enumerate(masks)}\n",
    "index_ade_map = {i:ade for i,ade in enumerate(ade_classes)}\n",
    "\n",
    "test_image_count = 10\n",
    "\n",
    "random_indexes = np.random.choice(list(index_img_map.keys()), test_image_count, replace=False)\n",
    "\n",
    "random_images = [index_img_map[index] for index in random_indexes]\n",
    "random_labels = np.array([index_label_map[index] for index in random_indexes])\n",
    "random_masks = [index_mask_map[index] for index in random_indexes]\n",
    "\n",
    "print(\"Total number of images \"+str(len(images)))\n",
    "print(\"Number of images used \"+str(len(random_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def encode_categorical_values(values: List[str]):\n",
    "    unique_values = sorted(list(set(values)))\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(unique_values)\n",
    "    return le\n",
    "\n",
    "label_encoder = encode_categorical_values(unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain using lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/4.0.3/libexec/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from lime import lime_image\n",
    "\n",
    "def explain_with_lime(images):\n",
    "    explainer = lime_image.LimeImageExplainer()\n",
    "    explanations = []\n",
    "    for i,image in enumerate(images):\n",
    "        lime_img_exp = explainer.explain_instance(np.array(image),\n",
    "                                                 classifier_fn=black_box_classify,\n",
    "                                                 top_labels=3,\n",
    "                                                 batch_size=100,\n",
    "                                                 num_samples=150,\n",
    "                                                 hide_color=None)\n",
    "        temp, mask = lime_img_exp.get_image_and_mask(lime_img_exp.top_labels[0], positive_only=False, num_features=10, hide_rest=False)\n",
    "        prediction_on_temp = black_box_lime(temp)\n",
    "\n",
    "        result = {\n",
    "            \"image\": image,\n",
    "            \"explanation\": temp,\n",
    "            \"mask\": mask,\n",
    "            \"prediction\": prediction_on_temp[0][0],\n",
    "            \"label\": random_labels[i]\n",
    "        }\n",
    "        explanations.append(result)\n",
    "    return explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain using the framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from typing import Dict, List\n",
    "\n",
    "def get_segments(img, mask, threshold=0.05):\n",
    "    segs = np.unique(mask)\n",
    "    segments = []\n",
    "    total = mask.shape[0] * mask.shape[1]\n",
    "    segments_classes = []\n",
    "    \n",
    "    for seg in segs:\n",
    "        idxs = mask == seg\n",
    "        sz = np.sum(idxs)\n",
    "        \n",
    "        if sz < threshold * total:\n",
    "            continue\n",
    "        \n",
    "        coords = np.argwhere(idxs)\n",
    "        x_min, y_min = coords.min(axis=0)\n",
    "        x_max, y_max = coords.max(axis=0)\n",
    "        \n",
    "        segment_img = img[x_min:x_max+1, y_min:y_max+1, :]\n",
    "        \n",
    "        segments.append(segment_img)\n",
    "        segments_classes.append(ade_classes['Name'].loc[ade_classes['Idx'] == seg].iloc[0])\n",
    "    \n",
    "    return segments, segments_classes\n",
    "\n",
    "def sort_dictionary(source: Dict[any, any], by_value=True, reverse=True) -> List[any]:\n",
    "    if by_value:\n",
    "        return sorted(source.items(), key=itemgetter(1), reverse=reverse)\n",
    "    return sorted(source.items(), key=itemgetter(0), reverse=reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from mpire import WorkerPool\n",
    "from functools import reduce\n",
    "\n",
    "class MostPopularConcepts:\n",
    "    BATCH_SIZE = 10\n",
    "    MAX_WORKER_COUNT = 8\n",
    "\n",
    "    def __init__(self,l_labels,i_images,m_maks):\n",
    "        all_labels = np.array(l_labels)\n",
    "        chunk_size = max(1, int(all_labels.size / self.BATCH_SIZE))\n",
    "        self.labels_in_chunks = np.array_split(all_labels, chunk_size)\n",
    "        self.nr_of_jobs = min(self.MAX_WORKER_COUNT, len(self.labels_in_chunks))\n",
    "\n",
    "        self.label_images_map = {}\n",
    "        self.label_masks_map = {}\n",
    "\n",
    "        self.image_most_popular_concepts = self.static_most_popular_concepts(l_labels,i_images,m_maks)\n",
    "\n",
    "    def static_most_popular_concepts(self,l_labels,i_images,m_maks) -> Dict[str, List[any]]:\n",
    "        for label, image, mask in zip(l_labels,i_images,m_maks):\n",
    "            current_images = self.label_images_map.get(label, [])\n",
    "            current_maks = self.label_masks_map.get(label, [])\n",
    "\n",
    "            current_images.append(image)\n",
    "            current_maks.append(mask)\n",
    "\n",
    "            self.label_images_map[label] = current_images\n",
    "            self.label_masks_map[label] = current_maks\n",
    "\n",
    "        with WorkerPool(n_jobs=self.nr_of_jobs) as pool:\n",
    "            return reduce(lambda a, b: {**a, **b},\n",
    "                          pool.map(self.__extract_most_popular_concepts, self.labels_in_chunks))\n",
    "\n",
    "    def __extract_most_popular_concepts(self, l_labels: List[str]) -> Dict[str, List[any]]:\n",
    "        partial_results = {}\n",
    "        for label in  l_labels:\n",
    "            i_images = self.label_images_map[label]\n",
    "            m_masks = self.label_masks_map[label]\n",
    "            nr_of_images = len(i_images)\n",
    "            partial_results[label] = self.most_popular_concepts(images,m_masks, nr_of_images)\n",
    "        return partial_results\n",
    "\n",
    "    @staticmethod\n",
    "    def most_popular_concepts(i_images, m_masks, k) -> List[str]:\n",
    "        segment_count = {}\n",
    "        for pic, mask in zip(i_images, m_masks):\n",
    "            _, seg_class = get_segments(np.array(pic), mask, threshold=0.005)\n",
    "            for s in seg_class:\n",
    "                segment_count[s] = segment_count.get(s, 0) + 1\n",
    "        segment_count = sort_dictionary(segment_count)\n",
    "        return [s for s, _ in segment_count[:k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def get_segment_relative_size(segment: np.array, picture: np.array) -> float:\n",
    "    segment_area = float(segment.shape[0] * segment.shape[1])\n",
    "    picture_area = float(picture.shape[0] * picture.shape[1])\n",
    "    return round(segment_area / picture_area, 2)\n",
    "\n",
    "\n",
    "def get_training_row(top_concepts_for_label: List[str], pic, mask) -> np.array:\n",
    "    row = np.zeros(NR_OF_UNIQUE_CONCEPTS)\n",
    "    pic_as_array = np.array(pic)\n",
    "    segss, seg_class = get_segments(pic_as_array, mask, threshold=0.005)\n",
    "    for index,concept in enumerate(UNIQUE_CONCEPT_VALUES):\n",
    "        if concept in top_concepts_for_label and concept in seg_class:\n",
    "            segment = segss[seg_class.index(concept)]\n",
    "            row[index] = get_segment_relative_size(segment, pic_as_array)            \n",
    "    return row\n",
    "\n",
    "def train_decision_tree(x, y) -> DecisionTreeClassifier:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf\n",
    "\n",
    "def train_concept_explainer(all_labels,all_images,all_masks):\n",
    "    X, y = [], []\n",
    "    for label, pic, mask in zip(all_labels,all_images, all_masks):\n",
    "        most_popular_concepts_for_label = MOST_POPULAR_CONCEPTS[label]\n",
    "        row = get_training_row(most_popular_concepts_for_label, pic, mask)\n",
    "        label_as_nr = label_encoder.transform([label])\n",
    "        X.append(row)\n",
    "        y.append(label_as_nr[0])\n",
    "    return train_decision_tree(X,np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "class HumanReadableExplanation:\n",
    "    def __init__(self,\n",
    "                 true_label: Optional[str],\n",
    "                 predicted_label: str,\n",
    "                 feature_importance: List[dict[str, float]]):\n",
    "        self.true_label = true_label\n",
    "        self.predicted_label = predicted_label\n",
    "        self.feature_importance = feature_importance\n",
    "\n",
    "    def to_db_format(self) -> Dict[str, any]:\n",
    "        payload = {\n",
    "            \"trueLabel\": self.true_label,\n",
    "            \"predictedLabel\": self.predicted_label,\n",
    "            \"featureImportance\": self.feature_importance,\n",
    "        }\n",
    "        to_be_deleted = [key for key, value in payload.items() if value is None]\n",
    "        for key in to_be_deleted:\n",
    "            del payload[key]\n",
    "        return payload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanReadableExplanationService:\n",
    "    def __init__(self,\n",
    "                 feature_encoder: preprocessing.LabelEncoder,\n",
    "                 estimator: DecisionTreeClassifier):\n",
    "        self.feature_encoder = feature_encoder\n",
    "        self.estimator = estimator\n",
    "\n",
    "    def  human_readable_explanation(self, x_test, y_test, y_true) -> Dict[str, any]:\n",
    "        features = self.estimator.tree_.feature\n",
    "        node_indicator = self.estimator.decision_path(x_test)\n",
    "        leave_id = self.estimator.apply(x_test)\n",
    "\n",
    "        sample_id = 0\n",
    "        node_index = node_indicator.indices[node_indicator.indptr[sample_id]:\n",
    "                                            node_indicator.indptr[sample_id + 1]]\n",
    "\n",
    "        features_present_in_explanation = []\n",
    "\n",
    "        for node_id in node_index:\n",
    "            if leave_id[sample_id] != node_id:\n",
    "                readable_feature = self.feature_encoder.inverse_transform([features[node_id]])[0]\n",
    "                features_present_in_explanation.append(readable_feature)\n",
    "\n",
    "        true_label_message = f\"True label for this image: {label_encoder.inverse_transform(y_true)[0]}\"\n",
    "        predicted_label_message = f\"Predicted label for this image: {label_encoder.inverse_transform([y_test])[0]}\"\n",
    "\n",
    "        human_readable_explain = HumanReadableExplanation(\n",
    "            true_label=true_label_message,\n",
    "            predicted_label=predicted_label_message,\n",
    "            feature_importance=self.__feature_importance(features_present_in_explanation),\n",
    "        )\n",
    "        return human_readable_explain.to_db_format()\n",
    "\n",
    "    def __feature_importance(self, features_in_local_explanation: List[str]) -> List[Dict[str, float]]:\n",
    "        results = {feature: {\"featureName\": feature, \"global\": importance} for feature, importance in zip(self.feature_encoder.classes_, self.estimator.feature_importances_)}\n",
    "\n",
    "        feature_local_score = {feature: results[feature][\"global\"] for feature in features_in_local_explanation}\n",
    "        total_local_score = sum(feature_local_score.values())\n",
    "        feature_local_score = {k: v / total_local_score for k, v in feature_local_score.items()}\n",
    "\n",
    "        for feature_name in results:\n",
    "            local_score = feature_local_score.get(feature_name, 0)\n",
    "            global_score = results[feature_name][\"global\"]\n",
    "\n",
    "            local_score = round(100*local_score, 2)\n",
    "            global_score = round(100*global_score, 2)\n",
    "\n",
    "            results[feature_name][\"local\"] = local_score\n",
    "            results[feature_name][\"global\"] = global_score\n",
    "\n",
    "        return sorted(list(results.values()), key=lambda x: x[\"local\"], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_features():\n",
    "    with open(all_concepts_path) as f:\n",
    "        all_concepts = f.read().splitlines()\n",
    "    return encode_categorical_values(all_concepts)\n",
    "\n",
    "def explain_with_concepts(to_be_explained_images,model):\n",
    "    \n",
    "    feature_encoder = encode_categorical_features()\n",
    "\n",
    "    hre = HumanReadableExplanationService(feature_encoder=feature_encoder,\n",
    "                                          estimator=model)\n",
    "\n",
    "    explanations = []\n",
    "    for i,img in enumerate(to_be_explained_images):\n",
    "        image_label = labels[i]\n",
    "        \n",
    "        most_popular_concepts_for_label = MOST_POPULAR_CONCEPTS[image_label]\n",
    "        mask = index_mask_map[i]\n",
    "        \n",
    "        row = get_training_row(most_popular_concepts_for_label, img, mask)\n",
    "\n",
    "        prediction_as_nr = model.predict([row])\n",
    "        correct_label_as_nr = label_encoder.transform([image_label])\n",
    "\n",
    "        explanation = hre.human_readable_explanation(x_test=[row],\n",
    "                                                 y_test=prediction_as_nr,\n",
    "                                                 y_true=correct_label_as_nr) # TODO: this is wrong\n",
    "        explanations.append(explanation)\n",
    "    return explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOST_POPULAR_CONCEPTS = MostPopularConcepts(labels,images,masks).image_most_popular_concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_explanations = explain_with_lime(random_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#to_be_trained_labels = [label for i,label in enumerate(labels) if i not in random_indexes]\n",
    "#to_be_trained_images = [img for i,img in enumerate(images) if i not in random_indexes]\n",
    "#to_be_trained_masks = [mask for i,mask in enumerate(masks) if i not in random_indexes]\n",
    "\n",
    "concept_model = train_concept_explainer(labels,images,masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_explanations = explain_with_concepts(images,concept_model)\n",
    "concept_explanations = [pred for i,pred in enumerate(concept_explanations) if i in random_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_lime(explanation):\n",
    "    label_name = label_encoder.inverse_transform([explanation['prediction']])[0]\n",
    "    print(\"Prediction: \"+label_name)\n",
    "    \n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10, 10))\n",
    "\n",
    "    # Original image\n",
    "    # Temp image\n",
    "    temp = explanation['explanation'].astype(float)\n",
    "    temp /= np.max(temp)\n",
    "    ax1.imshow(temp)\n",
    "    ax1.set_title('LIME image')\n",
    "\n",
    "\n",
    "    # Mask on image\n",
    "    temp = explanation['explanation'].astype(float)\n",
    "    temp /= np.max(temp)\n",
    "    ax2.imshow(mark_boundaries(temp, explanation['mask']))\n",
    "    ax2.set_title('LIME image with masks')\n",
    "\n",
    "    # Image with mask applied\n",
    "    img_arr = np.array(explanation['image'])\n",
    "    img = img_arr.astype(float)\n",
    "    img /= np.max(img)\n",
    "    ax3.imshow(mark_boundaries(img, explanation['mask']))\n",
    "    ax3.set_title('Mask boundaries')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def visulize_concept_exp(explanation):\n",
    "    print(explanation[\"trueLabel\"])\n",
    "    print(explanation[\"predictedLabel\"])\n",
    "    \n",
    "    sorted_data = sorted(explanation['featureImportance'], key=lambda x: x['local'], reverse=True)\n",
    "    top_ten_concepts = sorted_data[:10]\n",
    "\n",
    "    \n",
    "    feature_names = [item['featureName'] for item in top_ten_concepts]\n",
    "    # global_importance = [item['global'] for item in top_ten_concepts]\n",
    "    local_importance = [item['local'] for item in top_ten_concepts]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    ax.barh(feature_names,local_importance , color='blue', label='Gini Importance')\n",
    "\n",
    "    # ax.plot( global_importance, feature_names, 'o', color='red', markersize=8, label='Global Importance')\n",
    "\n",
    "    ax.set_xlabel('Importance')\n",
    "    ax.set_ylabel('Concept Name')\n",
    "    ax.set_title('Concept Importance')\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import PIL.IcoImagePlugin\n",
    "import PIL.Image\n",
    "import uuid\n",
    "import os\n",
    "from skimage.segmentation import mark_boundaries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def temp_img(index):\n",
    "    image_pil = random_images[index]\n",
    "    temp_image_path = str(uuid.uuid4())+\".jpg\"\n",
    "    image_pil.save(temp_image_path)\n",
    "    return temp_image_path\n",
    "\n",
    "def vizualise_img(path):\n",
    "    open_image = Image.open(path)\n",
    "    plt.imshow(open_image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    os.remove(path)\n",
    "\n",
    "def vizualise_explanation(index):\n",
    "    correct_label = random_labels[index]\n",
    "    \n",
    "    temp_image_path = temp_img(index)\n",
    "    vizualise_img(temp_image_path)\n",
    "    \n",
    "    print(\"Correct label: \"+correct_label)\n",
    "    \n",
    "    lime_explanation = lime_explanations[index]\n",
    "    print(\"\")\n",
    "    print(\"LIME explanation\")\n",
    "    print(\"\")\n",
    "    visualize_lime(lime_explanation)\n",
    "    print(\"\")\n",
    "    print(\"Concept explanation\")\n",
    "    print(\"\")\n",
    "    concept_explanation = concept_explanations[index]\n",
    "    visulize_concept_exp(concept_explanation)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Image 1\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mvizualise_explanation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[21], line 26\u001b[0m, in \u001b[0;36mvizualise_explanation\u001b[0;34m(index)\u001b[0m\n\u001b[1;32m     23\u001b[0m correct_label \u001b[38;5;241m=\u001b[39m random_labels[index]\n\u001b[1;32m     25\u001b[0m temp_image_path \u001b[38;5;241m=\u001b[39m temp_img(index)\n\u001b[0;32m---> 26\u001b[0m \u001b[43mvizualise_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_image_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCorrect label: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mcorrect_label)\n\u001b[1;32m     30\u001b[0m lime_explanation \u001b[38;5;241m=\u001b[39m lime_explanations[index]\n",
      "Cell \u001b[0;32mIn[21], line 16\u001b[0m, in \u001b[0;36mvizualise_img\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvizualise_img\u001b[39m(path):\n\u001b[0;32m---> 16\u001b[0m     open_image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241m.\u001b[39mopen(path)\n\u001b[1;32m     17\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(open_image)\n\u001b[1;32m     18\u001b[0m     plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "# Image 1\n",
    "print(vizualise_explanation(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
