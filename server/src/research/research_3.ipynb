{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research question 3: How meaningful are the extracted concepts?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r -q requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from skimage.transform import resize\n",
    "\n",
    "blackbox_model = ResNet50(weights='imagenet', include_top=True, input_shape=(224, 224, 3))\n",
    "\n",
    "def preprocess_images(img_array):\n",
    "    img_array = np.array([tf.image.resize(img_to_array(img), (224, 224)) for img in img_array])\n",
    "    return preprocess_input(img_array)\n",
    "\n",
    "def black_box_classify(img_array,convert_to_nr=True):\n",
    "    preprocessed_imgs = preprocess_images(img_array)\n",
    "    predictions = blackbox_model.predict(preprocessed_imgs)\n",
    "    prediction_labels = decode_predictions(predictions, top = 1)\n",
    "    labels_as_str = [row[0][1] for row in prediction_labels]\n",
    "    if convert_to_nr:\n",
    "        label_as_nr = label_encoder.transform(labels_as_str)\n",
    "        return [[l]for l in label_as_nr]\n",
    "    return [[l]for l in labels_as_str]\n",
    "\n",
    "def black_box_lime(temp):\n",
    "    resized_temp = resize(temp, (224, 224), mode='reflect', preserve_range=True).astype(np.uint8)\n",
    "    resized_temp = np.expand_dims(resized_temp, axis=0)\n",
    "    predictions = blackbox_model.predict(resized_temp)\n",
    "    prediction_labels = decode_predictions(predictions, top = 1)\n",
    "    labels_as_str = [row[0][1] for row in prediction_labels]\n",
    "    label_as_nr = label_encoder.transform(labels_as_str)\n",
    "    return [[l]for l in label_as_nr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8/50 [===>..........................] - ETA: 23s"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "base_path = \"/Users/karlgustav/Documents/GitHub/study/master-thesis/server/src/research/\"\n",
    "# base_path = \"/Users/karl-gustav.kallasmaa/Documents/Projects/master-thesis/server/src/\"\n",
    "all_labels_path = f\"{base_path}all_classes.txt\"\n",
    "all_concepts_path = f\"{base_path}all_concepts.txt\"\n",
    "masks_path = f\"{base_path}data/masks.pkl\"\n",
    "img_path = f\"{base_path}data/resized_imgs.pkl\"\n",
    "labels_path = f\"{base_path}data/classes.pkl\"\n",
    "ade_path = f\"{base_path}data/objectInfo150.csv\"\n",
    "\n",
    "ade_classes = pd.read_csv(ade_path)\n",
    "\n",
    "images = []\n",
    "masks = []\n",
    "unique_labels = []\n",
    "with open(masks_path, 'rb') as f:\n",
    "    masks = pickle.load(f)\n",
    "with open(img_path, 'rb') as f:\n",
    "    images = pickle.load(f)\n",
    "with open(all_labels_path) as f:\n",
    "    lines = f.read().splitlines()\n",
    "    lines = [l.replace(' ', '_') for l in lines]\n",
    "    unique_labels = np.array(list(set(lines)))\n",
    "\n",
    "labels = black_box_classify(images,False)\n",
    "labels = [l[0] for l in labels]\n",
    "\n",
    "all_concept_values = ade_classes['Name'].tolist()\n",
    "UNIQUE_CONCEPT_VALUES = sorted(list(set(all_concept_values)))\n",
    "NR_OF_UNIQUE_CONCEPTS = len(UNIQUE_CONCEPT_VALUES)\n",
    "\n",
    "\n",
    "image_hex_index_map = {hashlib.sha1(np.array(img).view(np.uint8)).hexdigest(): i for i,img in enumerate(images)}\n",
    "\n",
    "index_img_map = {i:img for i,img in enumerate(images)}\n",
    "index_label_map = {i:label for i,label in enumerate(labels)}\n",
    "index_mask_map = {i:mask for i,mask in enumerate(masks)}\n",
    "index_ade_map = {i:ade for i,ade in enumerate(ade_classes)}\n",
    "\n",
    "test_image_count = 10\n",
    "\n",
    "random_indexes = np.random.choice(list(index_img_map.keys()), test_image_count, replace=False)\n",
    "\n",
    "random_images = [index_img_map[index] for index in random_indexes]\n",
    "random_labels = np.array([index_label_map[index] for index in random_indexes])\n",
    "random_masks = [index_mask_map[index] for index in random_indexes]\n",
    "\n",
    "print(\"Total number of images \"+str(len(images)))\n",
    "print(\"Number of images used \"+str(len(random_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propose concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from typing import Dict, List\n",
    "\n",
    "def get_segments(img, mask, threshold=0.05):\n",
    "    segs = np.unique(mask)\n",
    "    segments = []\n",
    "    total = mask.shape[0] * mask.shape[1]\n",
    "    segments_classes = []\n",
    "    \n",
    "    for seg in segs:\n",
    "        idxs = mask == seg\n",
    "        sz = np.sum(idxs)\n",
    "        \n",
    "        if sz < threshold * total:\n",
    "            continue\n",
    "        \n",
    "        coords = np.argwhere(idxs)\n",
    "        x_min, y_min = coords.min(axis=0)\n",
    "        x_max, y_max = coords.max(axis=0)\n",
    "        \n",
    "        segment_img = img[x_min:x_max+1, y_min:y_max+1, :]\n",
    "        \n",
    "        segments.append(segment_img)\n",
    "        segments_classes.append(ade_classes['Name'].loc[ade_classes['Idx'] == seg].iloc[0])\n",
    "    \n",
    "    return segments, segments_classes\n",
    "\n",
    "def sort_dictionary(source: Dict[any, any], by_value=True, reverse=True) -> List[any]:\n",
    "    if by_value:\n",
    "        return sorted(source.items(), key=itemgetter(1), reverse=reverse)\n",
    "    return sorted(source.items(), key=itemgetter(0), reverse=reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from mpire import WorkerPool\n",
    "from functools import reduce\n",
    "\n",
    "class MostPopularConcepts:\n",
    "    BATCH_SIZE = 10\n",
    "    MAX_WORKER_COUNT = 8\n",
    "\n",
    "    def __init__(self,l_labels,i_images,m_maks):\n",
    "        all_labels = np.array(l_labels)\n",
    "        chunk_size = max(1, int(all_labels.size / self.BATCH_SIZE))\n",
    "        self.labels_in_chunks = np.array_split(all_labels, chunk_size)\n",
    "        self.nr_of_jobs = min(self.MAX_WORKER_COUNT, len(self.labels_in_chunks))\n",
    "\n",
    "        self.label_images_map = {}\n",
    "        self.label_masks_map = {}\n",
    "\n",
    "        self.image_most_popular_concepts = self.static_most_popular_concepts(l_labels,i_images,m_maks)\n",
    "\n",
    "    def static_most_popular_concepts(self,l_labels,i_images,m_maks) -> Dict[str, List[any]]:\n",
    "        for label, image, mask in zip(l_labels,i_images,m_maks):\n",
    "            current_images = self.label_images_map.get(label, [])\n",
    "            current_maks = self.label_masks_map.get(label, [])\n",
    "\n",
    "            current_images.append(image)\n",
    "            current_maks.append(mask)\n",
    "\n",
    "            self.label_images_map[label] = current_images\n",
    "            self.label_masks_map[label] = current_maks\n",
    "\n",
    "        with WorkerPool(n_jobs=self.nr_of_jobs) as pool:\n",
    "            return reduce(lambda a, b: {**a, **b},\n",
    "                          pool.map(self.__extract_most_popular_concepts, self.labels_in_chunks))\n",
    "\n",
    "    def __extract_most_popular_concepts(self, l_labels: List[str]) -> Dict[str, List[any]]:\n",
    "        partial_results = {}\n",
    "        for label in  l_labels:\n",
    "            i_images = self.label_images_map[label]\n",
    "            m_masks = self.label_masks_map[label]\n",
    "            nr_of_images = len(i_images)\n",
    "            partial_results[label] = self.most_popular_concepts(images,m_masks, nr_of_images)\n",
    "        return partial_results\n",
    "\n",
    "    @staticmethod\n",
    "    def most_popular_concepts(i_images, m_masks, k) -> List[str]:\n",
    "        segment_count = {}\n",
    "        for pic, mask in zip(i_images, m_masks):\n",
    "            _, seg_class = get_segments(np.array(pic), mask, threshold=0.005)\n",
    "            for s in seg_class:\n",
    "                segment_count[s] = segment_count.get(s, 0) + 1\n",
    "        segment_count = sort_dictionary(segment_count)\n",
    "        if len(segment_count) < k:\n",
    "            return [s for s, _ in segment_count]\n",
    "        return [s for s, _ in segment_count[:k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpc_service = MostPopularConcepts(labels,images,masks)\n",
    "MOST_POPULAR_CONCEPTS = mpc_service.image_most_popular_concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate random concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_concepts(correct_concepts,label,image,mask,random_concept_count=4):\n",
    "    popular_concepts_in_img = mpc_service.most_popular_concepts([image],[mask],1000)\n",
    "    popular_concepts_in_img = [c for c in popular_concepts_in_img if c not in correct_concepts]\n",
    "    if len(popular_concepts_in_img) >= random_concept_count:\n",
    "        return [c for c in popular_concepts_in_img[:random_concept_count]]\n",
    "    \n",
    "    all_labels = list(MOST_POPULAR_CONCEPTS.keys())\n",
    "    all_labels = [l for l in all_labels if l != label]\n",
    "    \n",
    "    while True:\n",
    "        if len(popular_concepts_in_img) >= random_concept_count:\n",
    "            return [c for c in popular_concepts_in_img[:random_concept_count]]\n",
    "        random_label = random.choice(all_labels)\n",
    "        random_concepts = [c for c in MOST_POPULAR_CONCEPTS[random_label] if c not in correct_concepts]\n",
    "        random_concepts = [c for c in random_concepts if c not in popular_concepts_in_img]\n",
    "        popular_concepts_in_img = popular_concepts_in_img + random_concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate not random concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def get_segment_relative_size(segment: np.array, picture: np.array) -> float:\n",
    "    segment_area = float(segment.shape[0] * segment.shape[1])\n",
    "    picture_area = float(picture.shape[0] * picture.shape[1])\n",
    "    return round(segment_area / picture_area, 2)\n",
    "\n",
    "\n",
    "def get_training_row(top_concepts_for_label: List[str], pic, mask) -> np.array:\n",
    "    row = np.zeros(NR_OF_UNIQUE_CONCEPTS)\n",
    "    pic_as_array = np.array(pic)\n",
    "    segss, seg_class = get_segments(pic_as_array, mask, threshold=0.005)\n",
    "    for index,concept in enumerate(UNIQUE_CONCEPT_VALUES):\n",
    "        if concept in top_concepts_for_label and concept in seg_class:\n",
    "            segment = segss[seg_class.index(concept)]\n",
    "            row[index] = get_segment_relative_size(segment, pic_as_array)            \n",
    "    return row\n",
    "\n",
    "def train_decision_tree(x, y) -> DecisionTreeClassifier:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf\n",
    "\n",
    "def train_concept_explainer(all_labels,all_images,all_masks):\n",
    "    X, y = [], []\n",
    "    for label, pic, mask in zip(all_labels,all_images, all_masks):\n",
    "        most_popular_concepts_for_label = MOST_POPULAR_CONCEPTS[label]\n",
    "        row = get_training_row(most_popular_concepts_for_label, pic, mask)\n",
    "        label_as_nr = label_encoder.transform([label])\n",
    "        X.append(row)\n",
    "        y.append(label_as_nr[0])\n",
    "    return train_decision_tree(X,np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_values(values: List[str]):\n",
    "    unique_values = sorted(list(set(values)))\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(unique_values)\n",
    "    return le\n",
    "def encode_categorical_features():\n",
    "    with open(all_concepts_path) as f:\n",
    "        all_concepts = f.read().splitlines()\n",
    "    return encode_categorical_values(all_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_encoder = encode_categorical_features()\n",
    "label_encoder = encode_categorical_values(unique_labels)\n",
    "#estimator = train_concept_explainer(labels,images,masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_predictive_concepts(target_label):\n",
    "    random_label = \"\"\n",
    "    for l in labels:\n",
    "        if l != target_label:\n",
    "            random_label = l\n",
    "            break\n",
    "    reformated_labels = []\n",
    "    for label in labels:\n",
    "        if label == target_label:\n",
    "            reformated_labels.append(target_label)\n",
    "        else:\n",
    "            reformated_labels.append(random_label)\n",
    "    \n",
    "    estimator = train_concept_explainer(reformated_labels,images,masks)\n",
    "    \n",
    "    feature_importance = {feature: {\"featureName\": feature, \"local\": importance} for feature, importance in\n",
    "                              zip(feature_encoder.classes_, estimator.feature_importances_)}\n",
    "\n",
    "    feature_importance = sorted(list(feature_importance.values()), key=lambda x: x[\"local\"], reverse=True)\n",
    "    return [feature[\"featureName\"] for feature in feature_importance]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from typing import List, Set\n",
    "\n",
    "max_predictive_concept_count = 2\n",
    "max_intuitive_concept_count = 2\n",
    "\n",
    "def combine_concepts(most_predictive_concepts: List[str],most_intuitive_concepts: List[str],\n",
    "                    concept_suggestion_limit=4) -> List[str]:\n",
    "    proposed_concepts = []\n",
    "    added_predictive_concepts, added_intuitive_concepts = set(), set()\n",
    "    initially_proposed_concepts = []\n",
    "\n",
    "    for combination in itertools.zip_longest(most_predictive_concepts, most_intuitive_concepts):\n",
    "        if len(proposed_concepts) >= concept_suggestion_limit:\n",
    "            return proposed_concepts[:concept_suggestion_limit]\n",
    "\n",
    "        predictive_concept, intuitive_concept = combination\n",
    "\n",
    "        if __should_append_intuitive_concept(predictive_concept, proposed_concepts, added_intuitive_concepts):\n",
    "                proposed_concepts.append(predictive_concept)\n",
    "                added_predictive_concepts.add(predictive_concept)\n",
    "        if __should_append_intuitive_concept(intuitive_concept, proposed_concepts, added_intuitive_concepts):\n",
    "                proposed_concepts.append(intuitive_concept)\n",
    "                added_intuitive_concepts.add(intuitive_concept)\n",
    "\n",
    "    return proposed_concepts[:concept_suggestion_limit] if len(\n",
    "            proposed_concepts) > concept_suggestion_limit else proposed_concepts\n",
    "    \n",
    "def __should_append_intuitive_concept(intuitive_concept: str,proposed_concepts: List[str],added_intuitive_concepts: Set[str]):\n",
    "    return intuitive_concept is not None and intuitive_concept not in proposed_concepts and len(added_intuitive_concepts) < max_intuitive_concept_count\n",
    "\n",
    "  \n",
    "def __should_append_predictive_concept(predictive_concept: str,proposed_concepts: List[str],added_predictive_concepts: Set[str]):\n",
    "    return predictive_concept is not None and predictive_concept not in proposed_concepts and len(added_predictive_concepts) < TOP_K_PREDICTIVE_CONCEPTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_solultions(l_labels,i_images,m_masks,correct_concept_count=4):\n",
    "    solutions = []\n",
    "    i = 0\n",
    "    for label,mask,image in zip(l_labels,i_images,m_masks):\n",
    "        most_predictive = most_predictive_concepts(label)\n",
    "        most_popular = MOST_POPULAR_CONCEPTS[label]\n",
    "        framework_proposed_concepts = combine_concepts(most_predictive,most_popular)  \n",
    "        \n",
    "        chosen_random_concepts = random_concepts(framework_proposed_concepts,label,mask,image)\n",
    "          \n",
    "        combined = framework_proposed_concepts + chosen_random_concepts\n",
    "        random.shuffle(combined)\n",
    "        \n",
    "        exp = {\n",
    "            \"nr\":i+1,\n",
    "            \"label\":label,\n",
    "            \"correct\":framework_proposed_concepts,\n",
    "            \"random\":chosen_random_concepts,\n",
    "            \"combined\":combined\n",
    "        }\n",
    "        solutions.append(exp)\n",
    "        i += 1\n",
    "    return solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = experiment_solultions(random_labels,random_images,random_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def temp_img(index):\n",
    "    image_pil = random_images[index]\n",
    "    temp_image_path = str(uuid.uuid4())+\".jpg\"\n",
    "    image_pil.save(temp_image_path)\n",
    "    return temp_image_path\n",
    "\n",
    "def vizualise_img(path):\n",
    "    open_image = Image.open(path)\n",
    "    plt.imshow(open_image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    os.remove(path)\n",
    "    \n",
    "def vizualise_explanation(index):\n",
    "    correct_label = random_labels[index]\n",
    "    \n",
    "    temp_image_path = temp_img(index)\n",
    "    vizualise_img(temp_image_path)\n",
    "    \n",
    "    solution = solutions[index]\n",
    "    print(\"Label: \"+solution[\"label\"])\n",
    "        \n",
    "    print(\"Correct concepts\")\n",
    "    print(solution[\"correct\"])\n",
    "    \n",
    "    \n",
    "    print(\"Combined concepts\")\n",
    "    print(solution[\"combined\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image 1\n",
    "# 6 7 8 9\n",
    "for i in range(10):\n",
    "    print(\"Image \"+str(i))\n",
    "    vizualise_explanation(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
