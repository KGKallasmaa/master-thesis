{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research question 1: Do concept-based explanations produce more faithful explanations than feature attribution methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 0:Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "base_path = \"/Users/karlgustav/Documents/GitHub/study/master-thesis/server/src/research/data/\"\n",
    "# base_path = \"/Users/karl-gustav.kallasmaa/Documents/Projects/master-thesis/server/src/\"\n",
    "masks_path = f\"{base_path}masks.pkl\"\n",
    "img_path = f\"{base_path}resized_imgs.pkl\"\n",
    "labels_path = f\"{base_path}classes.pkl\"\n",
    "ade_path = f\"{base_path}objectInfo150.csv\"\n",
    "\n",
    "with open(masks_path, 'rb') as f:\n",
    "    masks = pickle.load(f)\n",
    "with open(img_path, 'rb') as f:\n",
    "    imgs = pickle.load(f)\n",
    "with open(labels_path, 'rb') as f:\n",
    "    labels = np.array(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'main'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpre_explanation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_access\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_labels, get_images,get_masks,get_ade_classes\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhashlib\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'main'"
     ]
    }
   ],
   "source": [
    "from main.service.pre_explanation.data_access import get_labels, get_images,get_masks,get_ade_classes\n",
    "import hashlib\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "labels = get_labels()\n",
    "images = get_images()\n",
    "masks = get_masks()\n",
    "ade_classes = get_ade_classes()\n",
    "\n",
    "image_hex_index_map = {hashlib.sha1(np.array(img).view(np.uint8)).hexdigest(): i for i,img in enumerate(images)}\n",
    "\n",
    "index_img_map = {i:img for i,img in enumerate(images)}\n",
    "index_label_map = {i:label for i,label in enumerate(labels)}\n",
    "index_mask_map = {i:mask for i,mask in enumerate(masks)}\n",
    "index_ade_map = {i:ade for i,ade in enumerate(ade_classes)}\n",
    "\n",
    "random_indexes = np.random.choice(np.array(index_img_map.keys()))\n",
    "\n",
    "random_images = [index_img_map[index] for index in random_indexes]\n",
    "random_labels = [index_img_map[index] for index in random_indexes]\n",
    "random_masks = [index_mask_map[index] for index in random_indexes]\n",
    "random_ade = [index_ade_map[index] for index in random_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def encode_categorical_values(values: List[str]):\n",
    "    unique_values = sorted(list(set(values)))\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(unique_values)\n",
    "    return le\n",
    "\n",
    "label_encoder = encode_categorical_values(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Get lime predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime import lime_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lime'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lime_image\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mblack_box_classify\u001b[39m(img):\n\u001b[1;32m      4\u001b[0m     img_key \u001b[38;5;241m=\u001b[39m hashlib\u001b[38;5;241m.\u001b[39msha1(np\u001b[38;5;241m.\u001b[39marray(img)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8))\u001b[38;5;241m.\u001b[39mhexdigest()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lime'"
     ]
    }
   ],
   "source": [
    "\n",
    "def black_box_classify(img):\n",
    "    img_key = hashlib.sha1(np.array(img).view(np.uint8)).hexdigest()\n",
    "    img_index = image_hex_index_map[img_key]\n",
    "    return index_label_map[img_index]\n",
    "\n",
    "def explain_with_lime(images, num_samples=1000, num_features=10, hide_color=None):\n",
    "    explainer = lime_image.LimeImageExplainer()\n",
    "    explanations = []\n",
    "    for image in images:\n",
    "        # Reshape the image to (height, width, channels) format\n",
    "        image_reshaped = image.reshape(image.shape[:-1])\n",
    "        # Explain the image predictions using LIME\n",
    "        explanation = explainer.explain_instance(image_reshaped,\n",
    "                                                 classifier_fn=black_box_classify,\n",
    "                                                 top_labels=1,\n",
    "                                                 hide_color=hide_color,\n",
    "                                                 num_samples=num_samples,\n",
    "                                                 num_features=num_features)\n",
    "        explanations.append(explanation)\n",
    "    return explanations\n",
    "\n",
    "lime_predictions = explain_with_lime(random_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Get concept-based desision tree explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: fix this\n",
    "MOST_POPULAR_CONCEPTS = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1518711617.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[11], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    def explain_with_concepts(images):\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "from typing import List,Tuple\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def get_segment_relative_size(segment: np.array, picture: np.array) -> float:\n",
    "    segment_area = float(segment.shape[0] * segment.shape[1])\n",
    "    picture_area = float(picture.shape[0] * picture.shape[1])\n",
    "    return round(segment_area / picture_area, 2)\n",
    "\n",
    "def get_segments(img, mask, threshold=0.05):\n",
    "    segs = np.unique(mask)\n",
    "    segments = []\n",
    "    total = mask.shape[0] * mask.shape[1]\n",
    "    segments_classes = []\n",
    "    for seg in segs:\n",
    "        idxs = mask == seg\n",
    "        sz = np.sum(idxs)\n",
    "        if sz < threshold * total:\n",
    "            continue\n",
    "        segment = img * idxs[..., None]\n",
    "        w, h, _ = np.nonzero(segment)\n",
    "        segment = segment[np.min(w):np.max(w), np.min(h):np.max(h), :]\n",
    "        segments.append(segment)\n",
    "        segments_classes.append(ade_classes['Name'].loc[ade_classes['Idx'] == seg].iloc[0])\n",
    "    return segments, segments_classes\n",
    "\n",
    "def get_training_row(user_selected_concepts: List[str], pic, mask) -> np.array:\n",
    "    row = np.zeros(len(user_selected_concepts))\n",
    "    pic_as_array = np.array(pic)\n",
    "    segss, seg_class = get_segments(pic_as_array, mask, threshold=0.005)\n",
    "    for index, el in enumerate(user_selected_concepts):\n",
    "        if el in seg_class:\n",
    "            segment = segss[seg_class.index(el)]\n",
    "            row[index] = get_segment_relative_size(segment, pic_as_array)\n",
    "    return row\n",
    "\n",
    "def train_and_test_decision_tree(x, y) -> Tuple[DecisionTreeClassifier, float]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf, clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_concept_explainer(all_labels,all_images,all_masks):\n",
    "    X, y = [], []\n",
    "    for label, pic, mask in zip(all_labels,all_images, all_masks):\n",
    "        most_popular_concepts_for_label = MOST_POPULAR_CONCEPTS[label]\n",
    "        row = get_training_row(most_popular_concepts_for_label, pic, mask)\n",
    "        label_as_nr = label_encoder.transform([label])\n",
    "        X.append(row)\n",
    "        y.append(label_as_nr)\n",
    "    clf, accuracy = train_and_test_decision_tree(np.array(X), np.array(y))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_with_concepts(images,model):\n",
    "    predictions = []\n",
    "    for img in images:\n",
    "        img_key = hashlib.sha1(np.array(img).view(np.uint8)).hexdigest()\n",
    "        image_index = image_hex_index_map[img_key]\n",
    "        image_label = index_label_map[image_index]\n",
    "\n",
    "        most_popular_concepts_for_label = MOST_POPULAR_CONCEPTS[image_label]\n",
    "        mask = index_mask_map[image_index]\n",
    "        \n",
    "        row = get_training_row(most_popular_concepts_for_label, img, mask)\n",
    "        prediction_as_nr = model.predict([row])\n",
    "        prediction_as_label = label_encoder.inverse_transform(prediction_as_nr)\n",
    "        predictions.append(prediction_as_label)\n",
    "    return predictions\n",
    "\n",
    "concept_model = train_concept_explainer(labels,images,masks)\n",
    "concept_predictions = explain_with_concepts(random_images,concept_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: calculate fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m                 not_same \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m same \u001b[38;5;241m/\u001b[39m not_same\n\u001b[0;32m---> 23\u001b[0m black_box_pred \u001b[38;5;241m=\u001b[39m black_box_models_predictions(\u001b[43mrandom_images\u001b[49m)\n\u001b[1;32m     25\u001b[0m lime_fidelity \u001b[38;5;241m=\u001b[39m fidelity(pred1\u001b[38;5;241m=\u001b[39mlime_predictions,pred2\u001b[38;5;241m=\u001b[39mblack_box_pred)\n\u001b[1;32m     26\u001b[0m concept_fidelity \u001b[38;5;241m=\u001b[39m fidelity(pred1\u001b[38;5;241m=\u001b[39mconcept_predictions,pred2\u001b[38;5;241m=\u001b[39mblack_box_pred)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random_images' is not defined"
     ]
    }
   ],
   "source": [
    "def black_box_models_predictions(images):\n",
    "    predictions = []\n",
    "    for img in images:\n",
    "        img_key = hashlib.sha1(np.array(img).view(np.uint8)).hexdigest()\n",
    "        image_index = image_hex_index_map[img_key]\n",
    "        image_label = index_label_map[image_index]\n",
    "\n",
    "        predictions.append(image_label)\n",
    "    return predictions\n",
    "\n",
    "def fidelity(pred1,pred2):\n",
    "    same = 0\n",
    "    not_same = 0\n",
    "    for p1 in pred1:\n",
    "        for p2 in pred2:\n",
    "            if p1 == p2:\n",
    "                same += 1\n",
    "            else:\n",
    "                not_same += 1\n",
    "    return same / not_same\n",
    "\n",
    "\n",
    "black_box_pred = black_box_models_predictions(random_images)\n",
    "\n",
    "lime_fidelity = fidelity(pred1=lime_predictions,pred2=black_box_pred)\n",
    "concept_fidelity = fidelity(pred1=concept_predictions,pred2=black_box_pred)\n",
    "\n",
    "\n",
    "print(\"LIME fidelity \"+lime_fidelity)\n",
    "print(\"Concept fidelity\"+concept_fidelity)\n",
    "if lime_fidelity > concept_fidelity:\n",
    "    diff = lime_fidelity - concept_fidelity\n",
    "    print(\"LIME fidelity is greater than concept fidelity by \"+diff)\n",
    "else:\n",
    "    diff = concept_fidelity -lime_fidelity\n",
    "    print(\"Concept fidelity is creater than LIME fidelity by \"+diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd385fe162c5ca0c84973b7dd5c518456272446b2b64e67c2a69f949ca7a1754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
